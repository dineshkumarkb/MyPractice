{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging SageMaker Training Jobs with Tornasole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tornasole is a new capability of Amazon SageMaker that allows debugging machine learning training. \n",
    "It lets you go beyond just looking at scalars like losses and accuracies during training and gives \n",
    "you full visibility into all tensors 'flowing through the graph' during training.\n",
    "\n",
    "Using Tornasole is a two step process: Saving tensors and Analysis. Let's look at each one of them closely.\n",
    "\n",
    "### Saving tensors\n",
    "\n",
    "Tensors define the state of the training job at any particular instant in its lifecycle. Tornasole exposes a library which allows you to capture these tensors and save them for analysis. Tornasole is highly customizable to save the tesnsors you want at different frequencies. Refer [DeveloperGuide_PyTorch](../../DeveloperGuide_PyTorch.md) for details on how to save the tensors you want to save.\n",
    "\n",
    "### Analysis\n",
    "\n",
    "Analyses of the tensors emitted is captured by the Tornasole concept called ***Rules***. On a very broad level, \n",
    "A Rule is a python code used to detect certain conditions during training. Some of the conditions that a data scientist training a deep learning model may care about are monitoring for gradients getting too large or too small, detecting overfitting, and so on.\n",
    "Tornasole will come pre-packaged with certain rules. Users can write their own rules using the Tornasole APIs.\n",
    "You can also analyze raw tensor data outside of the Rules construct in say, a Sagemaker notebook, using Tornasole's full set of APIs. \n",
    "Please refer [DeveloperGuide_Rules](../../../rules/DeveloperGuide_Rules.md) for more details about analysis.\n",
    "\n",
    "This example guides you through installation of the required components for emitting tensors in a \n",
    "SageMaker training job and applying a rule over the tensors to monitor the live status of the job. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As a first step, we'll do the installation of required tools which will allow emission of tensors (saving tensors) and application of rules to analyze them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync s3://tornasole-external-preview-use1/ ~/tornasole-preview\n",
    "!pip -q install ~/tornasole-preview/sdk/sagemaker-tornasole-latest.tar.gz\n",
    "!aws configure add-model --service-model file://`echo ~/tornasole-preview/sdk/sagemaker-tornasole.json` --service-name sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've completed the setup, we're ready to spin off a training job with debugging enabled. \n",
    "\n",
    "## Enable Tornasole in the training script\n",
    "\n",
    "### Import the tornasole_hook package\n",
    "Import the TornasoleHook class along with other helper classes in your training script as shown below\n",
    "\n",
    "```\n",
    "from tornasole.pytorch import SaveConfig, TornasoleHook\n",
    "```\n",
    "\n",
    "### Instantiate and initialize tornasole hook\n",
    "\n",
    "```\n",
    "    # Create SaveConfig that instructs engine to log graph tensors every 10 steps.\n",
    "    save_config = SaveConfig(save_interval=10)\n",
    "    \n",
    "    # Create a hook that logs tensors of weights, biases and gradients while training the model.\n",
    "    \n",
    "    hook = TornasoleHook(save_config=save_config)\n",
    "```\n",
    "\n",
    "For additional details on TornasoleHook, SaveConfig and Collection please refer to the [API documentation](api.md)\n",
    "\n",
    "### Register Tornasole hook to the model before starting of the training.\n",
    "\n",
    "\n",
    "After creating or loading your desired model, you can register the hook with the model as shown below.\n",
    "\n",
    "```\n",
    "net = create_model()\n",
    "# Apply hook to the model\n",
    "# and enable mode in which engine will log graph tensors\n",
    "hook.register_hook(net)\n",
    "```\n",
    "\n",
    "#### Set the mode\n",
    "Tornasole has the concept of modes (TRAIN, EVAL, PREDICT) to separate out different modes of the jobs. Set the mode you are running in your job. Every time the mode changes in your job, please set the current mode. This helps you group steps by mode, for easier analysis. Setting the mode is optional but recommended. If you do not specify this, Tornasole saves all steps under a GLOBAL mode.\n",
    "\n",
    "\n",
    "```\n",
    "hook.set_mode(ts.modes.TRAIN)\n",
    "```\n",
    "\n",
    "Refer [DeveloperGuide_PyTorch.md](../../DeveloperGuide_TF.md) for more details on the APIs Tornasole provides to help you save the tensors in different forms at the frequency you want.\n",
    "\n",
    "#### Note\n",
    "Tornasole currently only works for single process training. We will support distributed training very soon. \n",
    "\n",
    "## Start Sagemaker training with Tornasole enabled\n",
    "\n",
    "We'll be training a simple Pytorch model using the script [simple.py](../scripts/simple.py).\n",
    "This will be done using SageMaker Pytorch 1.13.1 Container in Script Mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Inputs\n",
    "Configuring the inputs for the training job. The command line arguments taken by the script\n",
    "can be passed using the hyperparameters dictionary below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_script = '../scripts/simple.py'\n",
    "docker_image_name= '072677473360.dkr.ecr.us-west-2.amazonaws.com/tornasole-preprod-pytorch-1.1.0-cpu:latest'\n",
    "hyperparameters = {'epochs': 2, 'lr' : 0.01, 'momentum' : 0.9, 'tornasole-frequency' : 3, 'steps' : 10, 'hook-type' : 'saveall', 'random-seed' : True }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage\n",
    "The tensors saved by Tornasole are, by default, stored in the S3 output path of the training job, \n",
    "under the folder **`/tensors-<job name>`**. This is done to ensure that we don't end up accidentally \n",
    "overwriting the tensors from a training job with the others. Rules evaluation require separation of \n",
    "the tensors paths to be evaluated correctly.\n",
    "\n",
    "If you don't provide an S3 output path to the estimator, SageMaker creates one for you as:\n",
    "**`s3://sagemaker-<region>-<account_id>/`**\n",
    "\n",
    "\n",
    "This path is used to create a Tornasole Trial taken by Rules (see below). \n",
    "\n",
    "#### New Parameters\n",
    "The new parameters in Sagemaker Estimator to look out for are\n",
    "\n",
    "##### `debug` (bool)\n",
    "This indicates that debugging should be enabled for the training job. \n",
    "Setting this as `True` would make Tornasole available for use with the job\n",
    "\n",
    "##### `rules_specification` (list[*dict*])\n",
    "This is a list of python dictionaries, where each `dict` is of the following form:\n",
    "```\n",
    "{\n",
    "    \"RuleName\": <str> # The name of the class implementing the Tornasole Rule interface. (required)\n",
    "    \"SourceS3Uri\": <str> # S3 URI of the rule script containing the class in 'RuleName'. \n",
    "    If left empty, it would look for the class in one of the First Party rules already provided to you by Amazon. \n",
    "    If not, SageMaker will try to look for the rule class in the script\n",
    "    \"InstanceType\": <str> # The ml instance type in which the rule evaluation should run\n",
    "    \"VolumeSizeInGB\": <int> # The volume size to store the runtime artifacts from the rule evaluation\n",
    "    \"RuntimeConfigurations\": {\n",
    "        # Map defining the parameters required to instantiate the Rule class and\n",
    "        # parameters regarding invokation of the rule (start-step and end-step)\n",
    "        # This can be any parameter taken by the rule\n",
    "        <str>: <str>\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules\n",
    "Rules are the medium by which Tornasole executes a certain piece of code regularly on different steps of the job.\n",
    "They can be used to assert certain conditions during training, and raise Cloudwatch Events based on them that you can\n",
    "use to process in any way you like. \n",
    "\n",
    "A Trial in Tornasole's context\n",
    "refers to a training job. It is identified by the path where the saved tensors for the job are stored. \n",
    "A rule takes a `base_trial` which refers to the job whose run invokes the rule execution.\n",
    "A rule can optionally look at other jobs as well, passed using the ar `other_trials`. \n",
    "\n",
    "Tornasole comes with a set of first party rules (1P rules).\n",
    "You can also write your own rules looking at these 1P rules for inspiration. \n",
    "Refer [DeveloperGuide_Rules.md](../../../rules/DeveloperGuide_Rules.md) for more.\n",
    " \n",
    "Here we will talk about how to use Sagemaker to evalute these rules on the training jobs.\n",
    "##### 1P Rule \n",
    "If you want to use a 1P rule. Specify the RuleName field with the 1P RuleName, \n",
    "and the rule will be automatically applied. You can pass any parameters accepted by the \n",
    "rule as part of the RuntimeConfigurations dictionary. The arguments `base_trial` (and `other_trials` if \n",
    "taken by the rule) can be passed as the S3 path where the tensors for \n",
    "the trial are stored in the RuntimeConfigurations dictionary above.\n",
    "\n",
    "Here's a example of a complex configuration for the SimilarAcrossRuns (which accepts another trial and a regex pattern) \n",
    "where we ask for the rule to be invoked for the steps between 10 and 100.\n",
    "\n",
    "``` \n",
    "rules_specification = [\n",
    "    {\n",
    "      \"RuleName\": \"SimilarAcrossRuns\",\n",
    "      \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "      \"VolumeSizeInGB\": 10,\n",
    "      \"RuntimeConfigurations\": {\n",
    "         \"other_trials\": \"s3://sagemaker-<region>-<account_id>/past-job\",\n",
    "         \"include_regex\": \".*\",\n",
    "         \"start-step\": \"10\",\n",
    "         \"end-step\": \"100\"\n",
    "       }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "##### Custom rule\n",
    "In this case you need to define a custom rule class which inherits from `tornasole.rules.Rule` class.\n",
    "You need to provide Sagemaker the S3 location of the file which defines your custom rule classes as the value for the field `SourceS3Uri`.\n",
    "Again, you can pass any arguments taken by this rule through the RuntimeConfigurations dictionary. \n",
    "Note that the custom rules can only have arguments which expect a string as the value except the two arguments \n",
    "specifying trials to the Rule. Refer [DeveloperGuide_Rules.md](../../../rules/DeveloperGuide_Rules.md) for more.\n",
    "\n",
    "Here's an example:\n",
    "```\n",
    "rules_specification = [\n",
    "    {\n",
    "      \"RuleName\": \"CustomRule\",\n",
    "      \"SourceS3Uri\": \"s3://weiyou-tornasole-test/rule-script/custom_rule.py\",\n",
    "      \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "      \"VolumeSizeInGB\": 10,\n",
    "      \"RuntimeConfigurations\": {\n",
    "         \"threshold\" : \"0.5\"\n",
    "       }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "### Estimator\n",
    "Now we'll call the Sagemaker Pytorch Estimator to kick off a training job along with a rule to monitor the job.\n",
    "\n",
    "For the purposes of this demonstration let us use the simple.py script with the above hyperparameters dictionary.\n",
    "These good hyperparameters do not produce vanishing gradients, so you will see that the rule doesn't get fired.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Example Without Vanishing Gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sagemaker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-240d2b4bde09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msagemaker_execution_role\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_execution_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#sagemaker_execution_role = 'AmazonSageMaker-ExecutionRole-20190614T145575'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m estimator = PyTorch(role=sagemaker_execution_role,\n\u001b[1;32m      4\u001b[0m                   \u001b[0mbase_job_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pytorch-good-example'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mtrain_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sagemaker' is not defined"
     ]
    }
   ],
   "source": [
    "sagemaker_execution_role = sagemaker.get_execution_role()\n",
    "#sagemaker_execution_role = 'AmazonSageMaker-ExecutionRole-20190614T145575'\n",
    "estimator = PyTorch(role=sagemaker_execution_role,\n",
    "                  base_job_name='pytorch-good-example',\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.m4.xlarge',\n",
    "                  image_name=docker_image_name,\n",
    "                  entry_point=entry_point_script,\n",
    "                  framework_version='1.1.0',\n",
    "                  hyperparameters=hyperparameters,\n",
    "                  py_version='py3',\n",
    "                  debug=True,\n",
    "                  rules_specification=[\n",
    "                      {\n",
    "                          \"RuleName\": \"VanishingGradient\",\n",
    "                          \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "                          \"VolumeSizeInGB\": 10,\n",
    "                          \"RuntimeConfigurations\": {\n",
    "                              \"start-step\": \"1\",\n",
    "                              \"end-step\": \"50\"\n",
    "                          }\n",
    "                      }\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "As a result of the above command, SageMaker will spin off 2 training jobs for you - the first one being the job which produces the tensors to be analyzed and the second one, which evaluates or analyzes the rule you asked it to in `rules_specification`\n",
    "\n",
    "### Check the status of the Rule Execution Job\n",
    "To get the rule execution job that SageMaker started for you, run the command below and it shows you the `RuleName`, `RuleStatus`, `FailureReason` if any, and `RuleExecutionJobArn`. If the tensors meets a rule evaluation condition, the rule execution job throws a client error with `FailureReason: RuleEvaluationConditionMet`. You can check the Cloudwatch Logstream `/aws/sagemaker/TrainingJobs` with `RuleExecutionJobArn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.describe_rule_execution_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receive CloudWatch Event For your Jobs\n",
    "When the status of training job or rule execution job change (i.e. starting, failed), TrainingJobStatus CloudWatch events are emitted : https://docs.aws.amazon.com/sagemaker/latest/dg/cloudwatch-events.html. You can configure a CW event rule to receive and process these events by setting up a target (Lambda function, SNS). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Example With Vanishing Gradients \n",
    "\n",
    "Now let us change the hyperparameters dictionary to the below bad set of hyperparameters, which produce vanishing gradients \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_script = '../scripts/simple.py'\n",
    "docker_image_name= '072677473360.dkr.ecr.us-west-2.amazonaws.com/tornasole-preprod-pytorch-1.1.0-cpu:latest'\n",
    "bad_hyperparameters = {'epochs': 2, 'lr' : 1.0, 'momentum' : 0.9, 'tornasole-frequency' : 3, 'steps' : 10, 'hook-type' : 'saveall', 'random-seed' : True }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_execution_role = sagemaker.get_execution_role()\n",
    "#sagemaker_execution_role = 'AmazonSageMaker-ExecutionRole-20190614T145575'\n",
    "estimator = PyTorch(role=sagemaker_execution_role,\n",
    "                  base_job_name='pytorch-bad-example',\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.m4.xlarge',\n",
    "                  image_name=docker_image_name,\n",
    "                  entry_point=entry_point_script,\n",
    "                  framework_version='1.1.0',\n",
    "                  hyperparameters=bad_hyperparameters,\n",
    "                  py_version='py3',\n",
    "                  debug=True,\n",
    "                  rules_specification=[\n",
    "                      {\n",
    "                          \"RuleName\": \"VanishingGradient\",\n",
    "                          \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "                          \"VolumeSizeInGB\": 10,\n",
    "                          \"RuntimeConfigurations\": {\n",
    "                              \"start-step\": \"1\",\n",
    "                              \"end-step\": \"10\"\n",
    "                          }\n",
    "                      }\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.describe_rule_execution_jobs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
